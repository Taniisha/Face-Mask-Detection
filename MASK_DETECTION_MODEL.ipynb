{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"name":"MASK_DETECTION_MODEL.ipynb","provenance":[{"file_id":"https://github.com/Taniisha/Face-Mask-Detection/blob/master/FACE%20MASK%20DETECTION.ipynb","timestamp":1609449080733}],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"k4t5qoH7o2Qw"},"source":["from tensorflow.keras.models import load_model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mUly_-4Jo2Q_"},"source":["import cv2\n","import numpy as np\n","import tkinter\n","from tkinter import messagebox\n","import smtplib\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UI8F_VRJo2RB","outputId":"e50ce389-c4b5-437e-e230-5d45f4217667"},"source":["#initialize tkinter\n","\n","root = tkinter.Tk()    #to create root window with basic widgets\n","root.withdraw()        #to hide this window"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["''"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"Svtn0qsko2RE"},"source":["#loading the trained DL model\n","\n","model = load_model('mask_detection.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h7njycRao2RF"},"source":["#classifier to detect face\n","\n","face_det_classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dNvYGVwmo2RG"},"source":["#capture video using webcam\n","vid_source = cv2.VideoCapture(0)\n","\n","text_dict = {0 : \"MASKED\" , 1 : \"NO MASK\"}\n","rect_color_dict = {0 : (0,255,0) , 1 : (0,0,255)}\n","\n","while(vid_source.isOpened()):\n","    ret , img = vid_source.read()\n","    grayscale_img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n","    faces = face_det_classifier.detectMultiScale(grayscale_img , 1.3 , 5)\n","    \n","    for (x,y,w,h) in faces:\n","        face_img = grayscale_img[y:y+h , x:x+w ]\n","        resized_img = cv2.resize(face_img ,(112,112))\n","        normalized_img = resized_img/255.0\n","        reshaped_img = np.reshape(normalized_img,(1,112,112,1))\n","        result = model.predict(reshaped_img)\n","        \n","        label = np.argmax(result , axis=1)[0]      #argmax method is same as np.predict_classes which will predict the output as class, here our image is predicted by our model\n","        \n","        cv2.rectangle(img , (x,y) , (x+w,y+h) , rect_color_dict[label],4)\n","        #cv2.rectangle(img , (x,y-40) , (x+w,y+h) , rect_color_dict[label],-1)\n","        cv2.putText(img,text_dict[label] , (x,y-10) , cv2.FONT_HERSHEY_SIMPLEX , 0.8 , (28,252,249) , 2)\n","        \n","    cv2.imshow(\"mask_detection\" , img)\n","    key = cv2.waitKey(1)\n","    if(key == 27):\n","        break\n","cv2.destroyAllWindows()\n","vid_source.release()\n","            \n","        "],"execution_count":null,"outputs":[]}]}