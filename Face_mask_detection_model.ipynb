{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face mask detection model",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMuS2qBwYzpXKvOVVQ5B6+e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Taniisha/Face-Mask-Detection/blob/master/Face_mask_detection_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "why4CAcp3gZC"
      },
      "source": [
        "# setting the environment\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzDMWAT4czNE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c95fdd20-e756-4d35-a9f3-37a1a0c98894"
      },
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\r\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\r\n",
        "!apt-get update -qq 2>&1 > /dev/null\r\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\r\n",
        "from google.colab import auth\r\n",
        "auth.authenticate_user()\r\n",
        "from oauth2client.client import GoogleCredentials\r\n",
        "creds = GoogleCredentials.get_application_default()\r\n",
        "import getpass\r\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL \r\n",
        "vcode = getpass.getpass()\r\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 145480 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.23-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.23-0ubuntu1~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.23-0ubuntu1~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-Uw5i9z267t",
        "outputId": "62e2f5d7-c573-458a-f315-35d1fc2d0bc5"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZIoe-t84EZq"
      },
      "source": [
        "# **Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvZSocqQ4EE3",
        "outputId": "4c3791e3-0569-4732-e041-802de8d006e4"
      },
      "source": [
        "# changing the directory to th required directory to access the dataset\r\n",
        "\r\n",
        "import os\r\n",
        "\r\n",
        "os.chdir(\"/content/drive/MyDrive/Colab Notebooks/OpenCV\")\r\n",
        "Dataset = \"Dataset\"\r\n",
        "Data_Dir = os.listdir(Dataset)    #os. listdir() method in python is used to get the list of all files and directories in the specified directory.\r\n",
        "print(Data_Dir)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['with_mask', 'without_mask']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I09hwc-K4EBa"
      },
      "source": [
        "import cv2 \r\n",
        "import numpy as np\r\n",
        "from tensorflow.keras.utils import to_categorical   #Using the method to_categorical() , a numpy array (or) a vector which has integers that represent different categories, can be converted into a numpy array (or) a matrix which has binary values and has columns equal to the number of categories in the data.\r\n",
        "from sklearn.preprocessing import LabelBinarizer    #It assigns a unique v alue or number to each label in a categorical feature. \r\n",
        "from sklearn.model_selection import train_test_split   #to divide the dataset into train and test\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVbf0IHS3o5q"
      },
      "source": [
        "#dimensions of image\r\n",
        "\r\n",
        "img_rows , img_cols = 112,112\r\n",
        "images = []         #it will store all the final images(after gray scaling and resizing)\r\n",
        "labels = []         #it will contain labels corresponding to classes of image(withMask , withoutMask)\r\n",
        "\r\n",
        "for category in Data_Dir:\r\n",
        "  folder_path = os.path.join(Dataset , category)    #we are joining dataset folders with_mask and without_mask to access them\r\n",
        "  for img in os.listdir(folder_path):\r\n",
        "    img_path = os.path.join(folder_path,img)\r\n",
        "    img  = cv2.imread(img_path)\r\n",
        "\r\n",
        "    try:\r\n",
        "      #converting img into grayscale image\r\n",
        "      grayscale_img =  cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\r\n",
        "\r\n",
        "      #resizing the img \r\n",
        "      resized_img = cv2.resize(grayscale_img , (img_rows, img_cols))\r\n",
        "      images.append(resized_img)\r\n",
        "      labels.append(category)\r\n",
        "\r\n",
        "    except Exception as e:\r\n",
        "      print(\"Exception : \",e)\r\n",
        "    \r\n",
        "    \r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q76xCgMnDTYY"
      },
      "source": [
        "images = np.array(images)/255.0          #to have pixel values in the range 0-1, dividing all pixels values by the largest pixel value; that is 255. This is performed across all channels, regardless of the actual range of pixel values that are present in the image\r\n",
        "images = np.reshape(images , (images.shape[0], img_rows , img_cols,1))      #converting into 3Dmatrix\r\n",
        "                                                                   # 1 representing gray scale                                                                   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81yCQUT-GVhV"
      },
      "source": [
        "#performing one hot encoding on the labels (with_mask , without_mask) because we have string data\r\n",
        "lb = LabelBinarizer()\r\n",
        "labels = lb.fit_transform(labels)     #fitting and transforming data\r\n",
        "labels = to_categorical(labels)       #converting to categorical\r\n",
        "labels = np.array(labels)             #converting into array because our models understand data in the form of vector or array\r\n",
        "\r\n",
        "(train_X,test_X,train_y,test_y) = train_test_split(images,labels,test_size=0.25,random_state=0)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yfZ57F7KcPK"
      },
      "source": [
        "# **CNN model** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kW7_DJRdJgag"
      },
      "source": [
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense,Flatten,Dropout,Activation\r\n",
        "from keras.layers import Conv2D,MaxPooling2D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YKM5ngcL6c2"
      },
      "source": [
        "num_classes = 2   #since our output is binary(with_mask and without_mask)\r\n",
        "batch_size = 32\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abRwcMEwMNye",
        "outputId": "6707a6b9-4daf-4604-dbbf-7d072e5a8a62"
      },
      "source": [
        "model = Sequential()\r\n",
        "\r\n",
        "model.add(Conv2D(64,(3,3),input_shape = (img_rows,img_cols,1),activation='relu'))\r\n",
        "#model.add(Activation='relu')\r\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "\r\n",
        "model.add(Conv2D(128,(3,3),activation='relu'))\r\n",
        "#model.add(Activation='relu')\r\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\r\n",
        "\r\n",
        "model.add(Flatten())    #Flatten layer converts data into 1D array so that it can be fed to other layer\r\n",
        "model.add(Dropout(0.5))   #it is a regularization parameter to reduce overfitting\r\n",
        "\r\n",
        "model.add(Dense(64,activation='relu'))\r\n",
        "model.add(Dense(num_classes,activation='softmax'))\r\n",
        "\r\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 110, 110, 64)      640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 55, 55, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 53, 53, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 26, 26, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 86528)             0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 86528)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                5537856   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 130       \n",
            "=================================================================\n",
            "Total params: 5,612,482\n",
            "Trainable params: 5,612,482\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIDJW0a9cUHv"
      },
      "source": [
        "# **Train Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydkl8mioSqxn",
        "outputId": "5a1e17d7-97b2-45ad-875e-fcf33fa13516"
      },
      "source": [
        "from keras.optimizers import Adam\r\n",
        "\r\n",
        "epochs = 55\r\n",
        "\r\n",
        "model.compile(optimizer = Adam(lr=0.001), loss= 'categorical_crossentropy' , metrics=['accuracy'])\r\n",
        "\r\n",
        "fit_model = model.fit(train_X,train_y,epochs=epochs,validation_split=0.25)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/55\n",
            "14/14 [==============================] - 1s 40ms/step - loss: 0.0052 - accuracy: 0.9994 - val_loss: 0.3020 - val_accuracy: 0.9320\n",
            "Epoch 2/55\n",
            "14/14 [==============================] - 0s 26ms/step - loss: 0.0068 - accuracy: 0.9990 - val_loss: 0.4856 - val_accuracy: 0.9048\n",
            "Epoch 3/55\n",
            "14/14 [==============================] - 0s 26ms/step - loss: 0.0171 - accuracy: 0.9931 - val_loss: 0.3973 - val_accuracy: 0.9184\n",
            "Epoch 4/55\n",
            "14/14 [==============================] - 0s 26ms/step - loss: 0.0198 - accuracy: 0.9937 - val_loss: 0.3619 - val_accuracy: 0.9116\n",
            "Epoch 5/55\n",
            "14/14 [==============================] - 0s 26ms/step - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.4095 - val_accuracy: 0.9320\n",
            "Epoch 6/55\n",
            "14/14 [==============================] - 0s 26ms/step - loss: 0.0084 - accuracy: 0.9990 - val_loss: 0.3533 - val_accuracy: 0.9184\n",
            "Epoch 7/55\n",
            "14/14 [==============================] - 0s 26ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 0.3057 - val_accuracy: 0.9252\n",
            "Epoch 8/55\n",
            "14/14 [==============================] - 0s 26ms/step - loss: 0.0122 - accuracy: 0.9928 - val_loss: 0.2890 - val_accuracy: 0.9456\n",
            "Epoch 9/55\n",
            "14/14 [==============================] - 0s 26ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.3051 - val_accuracy: 0.9252\n",
            "Epoch 10/55\n",
            "14/14 [==============================] - 0s 26ms/step - loss: 0.0035 - accuracy: 0.9997 - val_loss: 0.4228 - val_accuracy: 0.9252\n",
            "Epoch 11/55\n",
            "14/14 [==============================] - 0s 26ms/step - loss: 0.0137 - accuracy: 0.9966 - val_loss: 0.4797 - val_accuracy: 0.8980\n",
            "Epoch 12/55\n",
            "14/14 [==============================] - 0s 26ms/step - loss: 0.0529 - accuracy: 0.9758 - val_loss: 0.7075 - val_accuracy: 0.8571\n",
            "Epoch 13/55\n",
            "14/14 [==============================] - 0s 26ms/step - loss: 0.0481 - accuracy: 0.9828 - val_loss: 0.4704 - val_accuracy: 0.9116\n",
            "Epoch 14/55\n",
            "14/14 [==============================] - 0s 26ms/step - loss: 0.0134 - accuracy: 0.9961 - val_loss: 0.1957 - val_accuracy: 0.9388\n",
            "Epoch 15/55\n",
            "14/14 [==============================] - 0s 26ms/step - loss: 0.0124 - accuracy: 0.9894 - val_loss: 0.2037 - val_accuracy: 0.9388\n",
            "Epoch 16/55\n",
            "14/14 [==============================] - 0s 26ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.2683 - val_accuracy: 0.9320\n",
            "Epoch 17/55\n",
            "14/14 [==============================] - 0s 26ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.3502 - val_accuracy: 0.9320\n",
            "Epoch 18/55\n",
            "14/14 [==============================] - 0s 26ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.3812 - val_accuracy: 0.9252\n",
            "Epoch 19/55\n",
            "14/14 [==============================] - 0s 27ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.3794 - val_accuracy: 0.9388\n",
            "Epoch 20/55\n",
            "14/14 [==============================] - 0s 26ms/step - loss: 5.9496e-04 - accuracy: 1.0000 - val_loss: 0.3716 - val_accuracy: 0.9320\n",
            "Epoch 21/55\n",
            "14/14 [==============================] - 0s 26ms/step - loss: 2.8768e-04 - accuracy: 1.0000 - val_loss: 0.3677 - val_accuracy: 0.9252\n",
            "Epoch 22/55\n",
            "14/14 [==============================] - 0s 26ms/step - loss: 0.0070 - accuracy: 0.9931 - val_loss: 0.3825 - val_accuracy: 0.9252\n",
            "Epoch 23/55\n",
            "14/14 [==============================] - 0s 26ms/step - loss: 0.0060 - accuracy: 0.9952 - val_loss: 0.4031 - val_accuracy: 0.9320\n",
            "Epoch 24/55\n",
            "14/14 [==============================] - 0s 26ms/step - loss: 6.4145e-04 - accuracy: 1.0000 - val_loss: 0.4072 - val_accuracy: 0.9388\n",
            "Epoch 25/55\n",
            "14/14 [==============================] - 0s 26ms/step - loss: 2.9537e-04 - accuracy: 1.0000 - val_loss: 0.3910 - val_accuracy: 0.9388\n",
            "Epoch 26/55\n",
            "14/14 [==============================] - 0s 27ms/step - loss: 2.4876e-04 - accuracy: 1.0000 - val_loss: 0.3890 - val_accuracy: 0.9320\n",
            "Epoch 27/55\n",
            "14/14 [==============================] - 0s 26ms/step - loss: 2.2588e-04 - accuracy: 1.0000 - val_loss: 0.3695 - val_accuracy: 0.9252\n",
            "Epoch 28/55\n",
            "14/14 [==============================] - 0s 26ms/step - loss: 9.9549e-05 - accuracy: 1.0000 - val_loss: 0.3737 - val_accuracy: 0.9320\n",
            "Epoch 29/55\n",
            "14/14 [==============================] - 0s 34ms/step - loss: 9.6676e-05 - accuracy: 1.0000 - val_loss: 0.3731 - val_accuracy: 0.9320\n",
            "Epoch 30/55\n",
            "14/14 [==============================] - 0s 26ms/step - loss: 1.3168e-04 - accuracy: 1.0000 - val_loss: 0.3766 - val_accuracy: 0.9252\n",
            "Epoch 31/55\n",
            "14/14 [==============================] - 0s 26ms/step - loss: 4.8718e-05 - accuracy: 1.0000 - val_loss: 0.3819 - val_accuracy: 0.9252\n",
            "Epoch 32/55\n",
            "14/14 [==============================] - 0s 26ms/step - loss: 7.7900e-05 - accuracy: 1.0000 - val_loss: 0.3843 - val_accuracy: 0.9252\n",
            "Epoch 33/55\n",
            "14/14 [==============================] - 0s 26ms/step - loss: 4.6646e-05 - accuracy: 1.0000 - val_loss: 0.3875 - val_accuracy: 0.9252\n",
            "Epoch 34/55\n",
            "14/14 [==============================] - 0s 26ms/step - loss: 1.0711e-04 - accuracy: 1.0000 - val_loss: 0.3895 - val_accuracy: 0.9252\n",
            "Epoch 35/55\n",
            "14/14 [==============================] - 0s 26ms/step - loss: 1.0054e-04 - accuracy: 1.0000 - val_loss: 0.3924 - val_accuracy: 0.9320\n",
            "Epoch 36/55\n",
            "14/14 [==============================] - 0s 27ms/step - loss: 4.4183e-05 - accuracy: 1.0000 - val_loss: 0.3868 - val_accuracy: 0.9320\n",
            "Epoch 37/55\n",
            "14/14 [==============================] - 0s 26ms/step - loss: 1.4085e-04 - accuracy: 1.0000 - val_loss: 0.4005 - val_accuracy: 0.9388\n",
            "Epoch 38/55\n",
            "14/14 [==============================] - 0s 26ms/step - loss: 1.5702e-04 - accuracy: 1.0000 - val_loss: 0.5590 - val_accuracy: 0.9184\n",
            "Epoch 39/55\n",
            "14/14 [==============================] - 0s 26ms/step - loss: 0.0617 - accuracy: 0.9882 - val_loss: 0.6173 - val_accuracy: 0.8707\n",
            "Epoch 40/55\n",
            "14/14 [==============================] - 0s 27ms/step - loss: 0.0596 - accuracy: 0.9768 - val_loss: 0.3409 - val_accuracy: 0.9184\n",
            "Epoch 41/55\n",
            "14/14 [==============================] - 0s 26ms/step - loss: 0.0338 - accuracy: 0.9838 - val_loss: 0.3891 - val_accuracy: 0.8912\n",
            "Epoch 42/55\n",
            "14/14 [==============================] - 0s 26ms/step - loss: 0.0292 - accuracy: 0.9938 - val_loss: 0.3984 - val_accuracy: 0.9116\n",
            "Epoch 43/55\n",
            "14/14 [==============================] - 0s 26ms/step - loss: 0.0212 - accuracy: 0.9947 - val_loss: 0.3482 - val_accuracy: 0.9116\n",
            "Epoch 44/55\n",
            "14/14 [==============================] - 0s 27ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3792 - val_accuracy: 0.9184\n",
            "Epoch 45/55\n",
            "14/14 [==============================] - 0s 26ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3887 - val_accuracy: 0.9184\n",
            "Epoch 46/55\n",
            "14/14 [==============================] - 0s 26ms/step - loss: 0.0124 - accuracy: 0.9953 - val_loss: 0.5709 - val_accuracy: 0.8912\n",
            "Epoch 47/55\n",
            "14/14 [==============================] - 0s 27ms/step - loss: 0.0458 - accuracy: 0.9832 - val_loss: 0.2846 - val_accuracy: 0.9116\n",
            "Epoch 48/55\n",
            "14/14 [==============================] - 0s 26ms/step - loss: 0.0130 - accuracy: 0.9966 - val_loss: 0.2252 - val_accuracy: 0.9456\n",
            "Epoch 49/55\n",
            "14/14 [==============================] - 0s 26ms/step - loss: 0.0281 - accuracy: 0.9880 - val_loss: 0.5199 - val_accuracy: 0.8980\n",
            "Epoch 50/55\n",
            "14/14 [==============================] - 0s 26ms/step - loss: 0.0209 - accuracy: 0.9910 - val_loss: 0.2865 - val_accuracy: 0.9320\n",
            "Epoch 51/55\n",
            "14/14 [==============================] - 0s 26ms/step - loss: 0.0095 - accuracy: 0.9947 - val_loss: 0.3011 - val_accuracy: 0.9320\n",
            "Epoch 52/55\n",
            "14/14 [==============================] - 0s 26ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.4253 - val_accuracy: 0.9320\n",
            "Epoch 53/55\n",
            "14/14 [==============================] - 0s 26ms/step - loss: 0.0125 - accuracy: 0.9952 - val_loss: 0.3122 - val_accuracy: 0.9320\n",
            "Epoch 54/55\n",
            "14/14 [==============================] - 0s 26ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.2817 - val_accuracy: 0.9320\n",
            "Epoch 55/55\n",
            "14/14 [==============================] - 0s 26ms/step - loss: 9.6109e-04 - accuracy: 1.0000 - val_loss: 0.3250 - val_accuracy: 0.9388\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSekUTmte1GQ"
      },
      "source": [
        "# **Save or Serializ the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imUXcfPFe6QG"
      },
      "source": [
        "model.save('mask_detection.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZEwH2YId_Sy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}